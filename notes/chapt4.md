# 4.1 CUDA内存模型概述
CPU和GPU的主存都采用**DRAM**, 低延迟内存使用的是**SRAM**。  <br>
GPU和CPU在内存层次结构设计中都使用相似的准则和模型。 主要区别在于：CUDA让我们能显示的控制内存。

## 4.1.2 CUDA内存模型
CUDA内存模型提出多种**可编程内存**的类型：寄存器、共享内存、本地内存、常量内存、纹理内存、全局内存。 <br>

### 4.1.2.1 寄存器
核函数中声明的一个没有其他修饰符的自变量，通常存储在寄存器中。
1. GPU上运行速度最快的内存空间。
2. 每个线程私有。
3. 生命周期与核函数的生命周期相同.
4. 不同架构对于每个线程最大寄存器数量有限制。一旦超出限制，会用本地内存替代多占用的寄存器。可以在代码中为每个核函数显式的加上额外信息，来帮助编译器进行优化。

### 4.1.2.2 本地内存
核函数中符合存储在寄存器中，但不能进入被该核函数分配的寄存器空间中的变量将溢出到本地内存。比如：
1. 在编译时使用未知索引引用的本地数组
2. 可能占用大量寄存器空间的较大本地结构体或数组
3. 任何不满足核函数寄存器限定条件的变量  

**本地内存中的变量本质上与全局内存在同一块存储区域，高延迟、低带宽！** <br>
对于计算能力2.0及以上的GPU来说，本地内存数据也是存储在每个SM的一级缓存和每个设备的二级缓存中。

### 4.1.2.3 共享内存
核函数里用\_\_shared\_\_修饰的变量存放在共享内存中。  <br>
每个SM有一定数量的由线程块分配的共享内存。共享内存的生命周期伴随整个线程块。 <br>
SM中的L1 cache和共享内存都使用64KB的片上内存。

### 4.1.2.4 常量内存
用\_\_constant\_\_修饰。
1. 常量变量必须在全局空间内和所有核函数之外进行声明。对同一编译单元中的所有核函数可见。
2. 核函数只能从常量内存中**读取**数据。
3. 常量内存必须在主机端使用 cudaMemcpyToSymbol(const void* symbol, const void* src, size_t count); 初始化。该函数将count个字节从src指向的内存复制到symbol指向的内存中。 这个变量存放在设备的全局内存或常量内存。
4. **每从一个常量内存中读取一次数据，都会广播给线程束里所有线程。** 因此，当线程束中所有线程都从相同的内存地址中读取数据时，常量内存表现最好。

### 4.1.2.5 纹理内存
纹理内存驻留在设备内存中，并在每个SM的只读缓存中缓存。

### 4.1.2.6 全局内存
用\_\_device\_\_修饰。
1. GPU上最大、最慢的内存。
2. 可以在任何SM设备上被访问，贯穿应用程序的整个生命周期。 <br>
全局内存常驻于设备内存中，可通过32、64、128字节的内存事务进行访问。这些内存事务必须自然对齐。


### 4.1.2.7 GPU缓存(不可编程)
GPU上由四种缓存：一级缓存、二级缓存、只读常量缓存、只读纹理缓存。<br>
每个SM有一个一级缓存，所有SM共享一个二级缓存。一级和二级缓存被用来存储本地内存和全局内存中的数据。 <br>
每个SM也有一个只读常量缓存和只读纹理缓存。

### 4.1.2.8 CUDA变量声明总结
![总结](../imgs/CUDA%E5%8F%98%E9%87%8F%E5%A3%B0%E6%98%8E%E6%80%BB%E7%BB%93.png)



# 4.2 内存管理

## 4.2.1 内存分配和释放

分配全局内存：cudaMalloc(void **devPtr, size_t count);   <br>
初始化：cudaMemset(void **devPtr, int value, size_t count);  (不要用)<br>
释放全局内存：cudaFree(void *devPtr, int value, size_t count);


## 4.2.2 内存传输
传输数据：cudaMemcpy(void *dst, const void *src, size_t count, kind);   kind有四种  <br>
CPU与GPU之间通过PCIe总线连接，其带宽比GPU芯片和GPU内存之间的带宽要低很多。 因此，尽量减少主机和设备之间的传输。

## 4.2.3 固定内存
1. **主机内存**默认是pageable，但是GPU不能在可分页主机内存上安全的访问数据(操作系统可能移动数据)。 当从可分页主机内存传输数据到设备内存时，**CUDA驱动程序先分配临时页面将主机数据复制到固定内存,再从固定内存传输给设备内存**。 
2. **也可以直接分配固定主机内存：cudaMallocHost(void \*\*devPtr, size_t count);  这样分配的主机内存是页面锁定的，设备可以直接访问。 由于设备可以直接访问，其带宽比可分页内存的读写带宽高得多。**  
3. 分配过多的固定内存可能会导致主机系统性能下降，因为减少了用于存储虚拟内存数据的可分页内存数量。

释放固定主机内存：cudaFreeHost(void *ptr);
